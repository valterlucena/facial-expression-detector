{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecção de expressoes faciais.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valterlucena/facial-expression-detector/blob/master/facial_expressions_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA1V6L2ILwX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
        "from keras.layers import AveragePooling2D, BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import SeparableConv2D\n",
        "from keras import layers\n",
        "from keras.regularizers import l2\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import os, cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubg6XhFOZKdN",
        "colab_type": "text"
      },
      "source": [
        "Para realizar o experimento, utilizaremos Python com o auxílio do keras, pandas e outras bibliotecas que nos auxiliará a manipular as imagens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVzeCRt8ZjyU",
        "colab_type": "text"
      },
      "source": [
        "Inicialmente, importaremos a base de imagens contendo rostos de diversas pessoas demonstrando emoções diferentes. Para cada pessoa, teremos duas imagens\n",
        "de cada emoção sendo elas: **felicidade, nojo, raiva, tristeza, medo e uma expressão neutra**. A base contém 72 fotos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CLq4cxIfsM_",
        "colab_type": "code",
        "outputId": "9c6cbde0-2eab-48e8-e5b4-ca305aaace66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "width = int(2835)\n",
        "heigth = int(3543)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S1Xs_K1a6j2",
        "colab_type": "text"
      },
      "source": [
        "Cada imagem tem uma dimensão de 3543 x 2835 e passará por um pré processamento antes de ser inputada no modelo de treinamento. Os trataremos que faremos serão os seguinte:\n",
        "\n",
        "\n",
        "*   Detecção de *bounding box* para face (com intuito de eliminar background)\n",
        "*   Redução de RGB para escala de cinza (com intuito de reduzir o espaço gasto e assim otimizar o treinamento)\n",
        "*   Redução das dimensões das imagens (com intuito de reduzir o espaço gasto e assim otimizar o treinamento).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyDdE5lgd9P1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8edb677a-8243-4082-f8c6-b4d7de9b79d3"
      },
      "source": [
        "!wget http://dlib.net/files/mmod_human_face_detector.dat.bz2 \n",
        "!bzip2 -dk mmod_human_face_detector.dat.bz2 "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-05 14:31:17--  http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 694709 (678K)\n",
            "Saving to: ‘mmod_human_face_detector.dat.bz2.1’\n",
            "\n",
            "mmod_human_face_det 100%[===================>] 678.43K   564KB/s    in 1.2s    \n",
            "\n",
            "2019-12-05 14:31:19 (564 KB/s) - ‘mmod_human_face_detector.dat.bz2.1’ saved [694709/694709]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDPoU5Ojj8kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import dlib\n",
        "\n",
        "# Carrega Rede neural convolucional para detecção de face\n",
        "dnnFaceDetector=dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")\n",
        "\n",
        "path = '/content/gdrive/My Drive/PercepcaoComputacional/faces/'\n",
        "imgfiles = [ifile for ifile in os.listdir(path) if ifile.endswith('.jpg')]\n",
        "images = []\n",
        "# As labels de cada emoção estão definidas no nome do arquivo\n",
        "labels = [label[-7][0] for label in imgfiles]\n",
        "for imgfile in imgfiles:\n",
        "    img = cv2.imread(path + imgfile)\n",
        "    # Aqui realizamos a mudança para a escala de cinza\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Reconhecemos a face\n",
        "    rects=dnnFaceDetector(gray,1)\n",
        "   \n",
        "    left,top,right,bottom=0,0,0,0\n",
        "\n",
        "    # Para todo rosto da imagem, é gerado um par com as coordenadas\n",
        "    # que definem o bounding box. Como temo apenas um rosto em cada\n",
        "    # imagem, sempre haverá apenas 1 interação nesse for\n",
        "    for (i,rect) in enumerate(rects):\n",
        "      left=rect.rect.left() #x1\n",
        "      top=rect.rect.top() #y1\n",
        "      right=rect.rect.right() #x2\n",
        "      bottom=rect.rect.bottom() #y2\n",
        "      width=right-left\n",
        "      height=bottom-top\n",
        "\n",
        "      # Realizamos a cropagem da imagem \n",
        "      img_crop=gray[top:top+height,left:left+width]\n",
        "      # Reduzimos sua dimensão para um valor predefinido\n",
        "      img = cv2.resize(img_crop,(200, 200), interpolation = cv2.INTER_AREA)\n",
        "      images.append(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOQV0wVnclUO",
        "colab_type": "text"
      },
      "source": [
        "A seguir temos uma imagem resultado de como ficou nossa base pós processamento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w90wcrHQQI6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8G72SQmc18z",
        "colab_type": "text"
      },
      "source": [
        "Realizamos o levantamento de quais categorias existem e mapeamos as expressões para valores numéricos para se adequar ao treinamento do keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w86tHUdFaCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_labels = list(set(labels))\n",
        "wi = {v: i for i, v in enumerate(unique_labels)}\n",
        "rwi = {i: v for i, v in enumerate(unique_labels)}\n",
        "num_labels = [wi[l] for l in labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sznKZqRpdNfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(rwi)\n",
        "print(wi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2M0zSODO06C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagesnp = np.array(images)\n",
        "imagesnp = imagesnp.reshape(-1, 200, 200,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XnBaaK6O_i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regularization = l2(0.01)\n",
        "img_input = Input((200, 200, 1))\n",
        "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        " \n",
        "# module 1\n",
        "residual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        " \n",
        "# module 2\n",
        "residual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        " \n",
        "# module 3\n",
        "residual = Conv2D(64, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        " \n",
        "# module 4\n",
        "residual = Conv2D(128, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "x = Conv2D(len(unique_labels), (3, 3), padding='same')(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "output = Activation('softmax',name='predictions')(x)\n",
        " \n",
        "model = Model(img_input, output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bsOYtBFHOnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_labels = keras.utils.to_categorical(num_labels)\n",
        "x, y = shuffle(imagesnp, cat_labels, random_state=42)\n",
        "x_train, x_test, y_train, y_test = tts(x, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k18JfbpnHVYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "validation_data = (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5kZe87pHV7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, validation_data=validation_data, epochs=EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}